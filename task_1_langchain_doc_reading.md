

## 一、RAG的基本概念，与fine tuning的对比

Retrieval Augmented Generation，检索增强生成，是一种提高大模型输出质量的技术。

大模型的缺点：

- 幻觉，生成错误的回答
- 不具备时效性
- 数据安全，可能泄漏敏感信息

RAG在实现上，通过引入外部知识库，来应对上述问题。

知识库通过结构化的数据（三元组）来存储信息，在处理问答时，先识别出问题中的实体进而定位到知识库中的实体，然后借助多跳查询以回答问题。

RAG需要的技术模块如下：

- 意图理解：处理用户提问的模糊性和不规范性
- 文档解析：将各种格式的外部数据（pdf, ppt）等转换成格式化数据方便后续处理
- 文档索引：将解析后的文本切分成若干chunk，并建立索引，方便后续查询。
- 向量嵌入：将chunk映射成文本向量，文本向量的质量很重要。
- 知识检索：将用户输入嵌入，并评估和chunk之间的相似度，需要语义理解。
- 重排序：对知识检索召回的候选回答进行重排，进一步提高相关性和准确度。
- 大模型生成：借助检索到的数据，生成符合上下文的、准确、连贯的回答。

与fine tuning的对比：

|            |                                            |                                          |
| ---------- | ------------------------------------------ | :--------------------------------------- |
| 特性       | RAG技术                                    | SFT模型微调                              |
| 知识更新   | 实时更新检索库，适合动态数据，无需频繁重训 | 存储静态信息，更新知识需要重新训练       |
| 外部知识   | 高效利用外部资源，适合各类数据库           | 可对齐外部知识，但对动态数据源不够灵活   |
| 数据处理   | 数据处理需求低                             | 需构建高质量数据集，数据限制可能影响性能 |
| 模型定制化 | 专注于信息检索和整合，定制化程度低         | 可定制行为，风格及领域知识               |
| 可解释性   | 答案可追溯，解释性高                       | 解释性相对低                             |
| 计算资源   | 需要支持检索的计算资源，维护外部数据源     | 需要训练数据集和微调资源                 |
| 延迟要求   | 数据检索可能增加延迟                       | 微调后的模型反应更快                     |
| 减少幻觉   | 基于实际数据，幻觉减少                     | 通过特定域训练可减少幻觉，但仍然有限     |
| 道德和隐私 | 处理外部文本数据时需要考虑隐私和道德问题   | 训练数据的敏感内容可能引发隐私问题       |
|            |                                            |                                          |

## 二、LangChain文档阅读

LangChain是一个用于开发大模型驱动的应用的框架。这些应用往往需要理解上下文，并依赖大模型进行推理。LangChain提供了从调试，到部署，到评估监控的一系列工具。其中LangChain和核心模块LangChainTemplate类为一系列任务提供了易于部署的参考架构。

LangChainTemplate提供了两个热门的RAG模板，分别是：

- Retrieval Augmented Generation: 利用数据（默认来自OpenAI）构造你的对话机器人。

- Local Retrieval Augmented Generation: 使用本地工具构造聊天机器人。


这类模板实现了基于文档或者数据库的聊天或者查询功能，实现的技术有：

- 重排序：基于Cohere公司的重排序技术。Cohere提供了一种plugin式的后处理工具，将用户查询和预搜索的结果作为大模型的输入，重新评估相关性。Cohere Reranking可以和lexical search以及semantic search搭配使用，可以显著提升top-3准确率。但是Cohere Reranking更多时候只能作为后处理工具，因为虽然和semantic search类似，但是无法在大规模文档、数据库上使用。
- 拟人迭代搜索：利用迭代更新的prompt决定检索目标以及检索结果的好坏。
- 父文档检索：找到小段chunk后，返回其所在的大段chunk以方便模型生成。
- LangChainTemplate额外支持半结构化数据以及时序数据的RAG。



在第一节中讨论过，意图理解用于处理用户提问的模糊性和不规范性。针对这一点，LangChainTemplate提供了两类手段，分别是询问转化和询问构建。



询问转化(Query Transformation):

- 假设性文本嵌入：利用问题构建一个假设性的文档，再利用其嵌入进行语义搜索。
- 重写-检索-阅读
- step-back prompt：生成一个原始问题的退化问题，参与检索
- RAG-Fusion:生成多个问题，对它们的检索结果使用reciprocal rank fusion做融合。



询问构建(Query Construction)，主要目的是应用于DSL(Domain Specific Language)构建更合适的询问以处理多种专业问题。



## 

